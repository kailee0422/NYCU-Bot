#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Information Agent
è² è²¬ç›£æ§ NYCU AI ç¶²ç«™ä¸¦æŠ“å–ç²çå…¬å‘Š
"""
import asyncio
from datetime import datetime
from typing import List, Optional
from urllib.parse import unquote

import aiohttp
from bs4 import BeautifulSoup

from models import AwardAnnouncement, AgentMessage, MessageType
from base_agent import BaseAgent
from config import ProcessedTracker


class InformationAgent(BaseAgent):
    """
    è³‡è¨Šä»£ç†
    è² è²¬å¾ç¶²ç«™æŠ“å–ç²çå…¬å‘Šä¸¦é€šçŸ¥ Father Agent
    """
    
    def __init__(self):
        super().__init__("InformationAgent")
        self.base_url = "https://ai.nycu.edu.tw/category/hot-news/"
        self.tracker = ProcessedTracker()
        
        # ç²çç›¸é—œé—œéµå­—
        self.award_keywords = [
            'è³€', 'æ­è³€', 'æ­å–œ', 'ç²ç', 'ç²å¾—', 'æ¦®ç²', 'æ¦®è†º',
            'ç•¶é¸', 'ç²é¸', 'å…¥é¸', 'å¾—ç', 'ç¬¬ä¸€', 'å† è»', 'äºè»',
            'å„ªç­‰', 'ç‰¹å„ª', 'ä½³ä½œ', 'å„ªå‹', 'è¡¨æš', 'æ®Šæ¦®', 'æ¦®è­½',
            'æœ€ä½³', 'å‚‘å‡º', 'å„ªç§€'
        ]
    
    async def handle_message(self, message: AgentMessage):
        """è™•ç†æ¥æ”¶åˆ°çš„è¨Šæ¯"""
        if message.msg_type == MessageType.STATUS_UPDATE:
            self.log_info(f"æ”¶åˆ°ç‹€æ…‹æ›´æ–°: {message.payload}")
    
    def _is_award_announcement(self, title: str, content: str = "") -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºç²çå…¬å‘Š"""
        text_to_check = title + " " + content
        return any(keyword in text_to_check for keyword in self.award_keywords)
    
    async def _fetch_image_from_page(
        self,
        session: aiohttp.ClientSession,
        url: str
    ) -> Optional[str]:
        """å¾å…¬å‘Šé é¢æŠ“å–åœ–ç‰‡"""
        try:
            async with session.get(url, timeout=30) as response:
                if response.status != 200:
                    return None
                
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                # å°‹æ‰¾æ–‡ç« å…§å®¹ä¸­çš„åœ–ç‰‡
                content_area = (
                    soup.find('div', class_='entry-content') or 
                    soup.find('article')
                )
                
                if content_area:
                    # å„ªå…ˆæ‰¾ img æ¨™ç±¤
                    img = content_area.find('img')
                    if img and img.get('src'):
                        img_url = img['src']
                        if not img_url.startswith('http'):
                            img_url = f"https://ai.nycu.edu.tw{img_url}"
                        return img_url
                    
                    # å‚™é¸ï¼šæ‰¾ figure ä¸­çš„åœ–ç‰‡
                    figure = content_area.find('figure')
                    if figure:
                        img = figure.find('img')
                        if img and img.get('src'):
                            img_url = img['src']
                            if not img_url.startswith('http'):
                                img_url = f"https://ai.nycu.edu.tw{img_url}"
                            return img_url
                
                return None
                
        except Exception as e:
            self.log_error(f"æŠ“å–åœ–ç‰‡å¤±æ•— {url}: {e}")
            return None
    
    async def _fetch_full_content(
        self,
        session: aiohttp.ClientSession,
        url: str
    ) -> str:
        """å¾å…¬å‘Šé é¢æŠ“å–å®Œæ•´å…§å®¹"""
        try:
            async with session.get(url, timeout=30) as response:
                if response.status != 200:
                    return ""
                
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                content_area = soup.find('div', class_='entry-content')
                if content_area:
                    # ç§»é™¤è…³æœ¬å’Œæ¨£å¼
                    for script in content_area(['script', 'style']):
                        script.decompose()
                    
                    # å–å¾—ç´”æ–‡å­—
                    text = content_area.get_text(separator='\n', strip=True)
                    return text[:1000]  # é™åˆ¶é•·åº¦
                
                return ""
                
        except Exception as e:
            self.log_error(f"æŠ“å–å…§å®¹å¤±æ•— {url}: {e}")
            return ""
    
    async def scan_for_announcements(self) -> List[AwardAnnouncement]:
        """æƒæç¶²ç«™ç²å–ç²çå…¬å‘Š"""
        self.log_info("ğŸ” é–‹å§‹æƒæç²çå…¬å‘Š...")
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(self.base_url, timeout=30) as response:
                    if response.status != 200:
                        self.log_error(f"ç„¡æ³•è¨ªå•ç¶²ç«™: {response.status}")
                        return []
                    
                    html = await response.text()
                
                soup = BeautifulSoup(html, 'html.parser')
                announcements = []
                
                # æ‰¾æ‰€æœ‰æ–‡ç« 
                articles = soup.find_all('article')
                self.log_info(f"æ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« ")
                
                for article in articles[:10]:  # æª¢æŸ¥æœ€æ–°10ç¯‡
                    try:
                        # æå–æ¨™é¡Œå’ŒURL
                        h2 = article.find('h2', class_='entry-title')
                        if not h2:
                            continue
                        
                        link = h2.find('a')
                        if not link:
                            continue
                        
                        title = link.get_text(strip=True)
                        url = unquote(link.get('href', ''))
                        
                        # æå–å…§å®¹æ‘˜è¦
                        content = ""
                        summary_div = article.find('div', class_='entry-summary')
                        if summary_div:
                            content = summary_div.get_text(strip=True)
                        elif article.find('div', class_='entry-content'):
                            content = article.find('div', class_='entry-content').get_text(strip=True)
                        
                        # æª¢æŸ¥æ˜¯å¦ç‚ºç²çå…¬å‘Š
                        if not self._is_award_announcement(title, content):
                            self.log_info(f"è·³ééç²çå…¬å‘Š: {title[:30]}...")
                            continue
                        
                        self.log_info(f"ğŸ‰ ç™¼ç¾ç²çå…¬å‘Š: {title}")
                        
                        # æŠ“å–å®Œæ•´å…§å®¹
                        if not content or len(content) < 50:
                            full_content = await self._fetch_full_content(session, url)
                            if full_content:
                                content = full_content
                            else:
                                content = title
                        
                        # æå–æ—¥æœŸ
                        date_published = datetime.now()
                        time_element = article.find('time', class_='entry-date published')
                        if time_element:
                            datetime_str = time_element.get('datetime', '')
                            try:
                                if datetime_str:
                                    dt = datetime.fromisoformat(
                                        datetime_str.replace('+08:00', '')
                                    )
                                    date_published = dt
                            except:
                                pass
                        
                        # æŠ“å–åœ–ç‰‡
                        image_url = await self._fetch_image_from_page(session, url)
                        if image_url:
                            self.log_info(f"   æ‰¾åˆ°åœ–ç‰‡: {image_url[:60]}...")
                        
                        # å»ºç«‹ç²çå…¬å‘Šç‰©ä»¶
                        announcement = AwardAnnouncement(
                            id="",
                            title=title,
                            content=content,
                            url=url,
                            date=date_published,
                            image_url=image_url
                        )
                        announcement.id = announcement.generate_id()
                        
                        # æª¢æŸ¥æ˜¯å¦å·²è™•ç†é
                        if self.tracker.is_processed(announcement.id):
                            self.log_info(f"   å·²è™•ç†éï¼Œè·³é")
                            continue
                        
                        announcements.append(announcement)
                        
                    except Exception as e:
                        self.log_error(f"è™•ç†æ–‡ç« å¤±æ•—: {e}")
                        continue
                
                self.log_info(f"âœ… æ‰¾åˆ° {len(announcements)} å€‹æ–°ç²çå…¬å‘Š")
                return announcements
                
        except Exception as e:
            self.log_error(f"æƒæå…¬å‘Šå¤±æ•—: {e}")
            return []
    
    async def check_and_notify(self):
        """æª¢æŸ¥æ–°å…¬å‘Šä¸¦é€šçŸ¥ Father Agent"""
        announcements = await self.scan_for_announcements()
        
        if not announcements:
            self.log_info("æ²’æœ‰ç™¼ç¾æ–°çš„ç²çå…¬å‘Š")
            return
        
        for announcement in announcements:
            self.log_info(f"ğŸ“¤ é€šçŸ¥ FatherAgent: {announcement.title[:40]}...")
            
            # ç™¼é€è¨Šæ¯çµ¦ Father Agent
            await self.send_message(
                receiver="FatherAgent",
                msg_type=MessageType.NEW_ANNOUNCEMENT,
                payload={
                    'announcement': announcement,
                    'timestamp': datetime.now().isoformat()
                }
            )
            
            # æ¨™è¨˜ç‚ºå·²è™•ç†
            self.tracker.mark_processed(announcement.id)
            
            # çŸ­æš«å»¶é²é¿å…éå¿«
            await asyncio.sleep(1)
    
    async def run_continuous(self, interval_minutes: int = 30):
        """æŒçºŒç›£æ§æ¨¡å¼"""
        self.log_info(f"ğŸ”„ é–‹å§‹æŒçºŒç›£æ§ (é–“éš”: {interval_minutes} åˆ†é˜)")
        
        while True:
            try:
                await self.check_and_notify()
                self.log_info(f"â° {interval_minutes} åˆ†é˜å¾Œå†æ¬¡æª¢æŸ¥...")
                await asyncio.sleep(interval_minutes * 60)
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.log_error(f"ç›£æ§éŒ¯èª¤: {e}")
                await asyncio.sleep(60)  # éŒ¯èª¤å¾Œç­‰å¾…1åˆ†é˜é‡è©¦
